{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tommy90112/AI-chat-robot/blob/main/%E8%82%A1%E7%A5%A8%E6%9F%A5%E8%A9%A2%E6%8E%A8%E8%96%A6RAG%E7%B3%BB%E7%B5%B1(%E5%8F%B0%E8%82%A1_%E5%8D%8A%E5%B0%8E%E9%AB%94_%E9%9B%BB%E5%AD%90%E9%9B%B6%E7%B5%84%E4%BB%B6_ETF_%E9%87%91%E8%9E%8D_%E7%87%9F%E5%BB%BA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "URL = \"https://drive.google.com/uc?export=download&id=1bwKlo0lYkGFIk4eFMwXLu72YLagBsgOK\"\n",
        "!wget -O faiss_db.zip \"$URL\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCy4hcBgcc-z",
        "outputId": "05fc2d32-3892-45d3-dcae-12a02825493f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-23 13:32:04--  https://drive.google.com/uc?export=download&id=1bwKlo0lYkGFIk4eFMwXLu72YLagBsgOK\n",
            "Resolving drive.google.com (drive.google.com)... 64.233.181.138, 64.233.181.102, 64.233.181.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|64.233.181.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://drive.usercontent.google.com/download?id=1bwKlo0lYkGFIk4eFMwXLu72YLagBsgOK&export=download [following]\n",
            "--2025-12-23 13:32:04--  https://drive.usercontent.google.com/download?id=1bwKlo0lYkGFIk4eFMwXLu72YLagBsgOK&export=download\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.183.132, 2607:f8b0:4001:c64::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.183.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23643 (23K) [application/octet-stream]\n",
            "Saving to: â€˜faiss_db.zipâ€™\n",
            "\n",
            "faiss_db.zip        100%[===================>]  23.09K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-12-23 13:32:06 (88.5 MB/s) - â€˜faiss_db.zipâ€™ saved [23643/23643]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip faiss_db.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhPQD5g0_l5Z",
        "outputId": "57692acc-e2df-49ed-deee-7753ccb0f606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  faiss_db.zip\n",
            "replace faiss_db/index.pkl? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. å®‰è£è¼‰å…¥å¿…è¦å¥—ä»¶"
      ],
      "metadata": {
        "id": "Cc-facvpBkIi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-community sentence-transformers faiss-cpu gradio openai"
      ],
      "metadata": {
        "id": "9JThdfm-CVZZ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-openai\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain"
      ],
      "metadata": {
        "id": "L1zqb7F8BMP3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "PTx3Q75QBp_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. è‡ªè¨‚ E5 embedding é¡åˆ¥"
      ],
      "metadata": {
        "id": "z13eoo6uCnTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomE5Embedding(HuggingFaceEmbeddings):\n",
        "    def embed_documents(self, texts):\n",
        "        texts = [f\"passage: {t}\" for t in texts]\n",
        "        return super().embed_documents(texts)\n",
        "\n",
        "    def embed_query(self, text):\n",
        "        return super().embed_query(f\"query: {text}\")"
      ],
      "metadata": {
        "id": "HkmvGTaECfTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. è¼‰å…¥ `faiss_db`"
      ],
      "metadata": {
        "id": "NkXNMQs5RbNG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = CustomE5Embedding(model_name=\"intfloat/multilingual-e5-small\")\n",
        "db = FAISS.load_local(\"faiss_db\", embedding_model, allow_dangerous_deserialization=True)\n",
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "LkELACdWCtpo",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. è¨­å®š LLM"
      ],
      "metadata": {
        "id": "GrHSAsjcRkXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "qefbHOaUDUvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "æˆ‘å€‘é€™é‚Šä½¿ç”¨ Groq çš„ APIæœå‹™\n",
        "\n",
        "æ¨¡å‹çš„éƒ¨åˆ†ä½¿ç”¨çš„æ˜¯ llama 3.3 70b çš„ç‰ˆæœ¬"
      ],
      "metadata": {
        "id": "ESe75T9ypx0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('Groq')"
      ],
      "metadata": {
        "id": "Xefdy-lkRtAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ],
      "metadata": {
        "id": "K7UiOKuTDD5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = \"llama-3.3-70b-versatile\"\n",
        "base_url=\"https://api.groq.com/openai/v1\""
      ],
      "metadata": {
        "id": "hxBoQJ-gihDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    base_url=base_url # ä½¿ç”¨ OpenAI æœ¬èº«ä¸éœ€è¦é€™æ®µ\n",
        ")"
      ],
      "metadata": {
        "id": "JnqlH0W9P2-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. æŒ‡ä»¤è¨­è¨ˆ"
      ],
      "metadata": {
        "id": "K0egxeawSR41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "é€™é‚Šçµ¦å®šçš„ç³»çµ±æŒ‡ä»¤ï¼Œæœ¬èº«æ˜¯è‚¡ç¥¨æ¨è–¦è«®è©¢å¸«ï¼Œæ ¹æ“šç”¨æˆ¶æçš„å•é¡Œï¼Œçµ¦äºˆå›ç­”åŠæ¨è–¦ã€‚\n",
        "\n",
        "ï¼ˆå¦‚ï¼šè‚¡ç¥¨ç·¨è™Ÿ2882çš„åŸºæœ¬è³‡æ–™ã€å°ç©é›»èˆ‡è¯é›»çš„æœ¬ç›Šæ¯”åˆ†åˆ¥ç‚ºå¤šå°‘ã€æ¨è–¦æˆ‘é«˜EPSçš„è‚¡ç¥¨ã€æƒ³æ‰¾é«˜è‚¡æ·¨å€¼è‚¡ç¥¨ã€æ¨è–¦æˆ‘ETFé«˜æ·¨å€¼è‚¡ç¥¨....ç­‰ç­‰ï¼‰\n",
        "\n",
        "ä¸¦ä¸”æœ‰é™å®šåªèƒ½ç”¨ç¹é«”ä¸­æ–‡ä¾†å›ç­”ï¼Œä»¥å…ä½¿ç”¨å¦‚è‹±æ–‡ç­‰å…¶ä»–èªè¨€å›ç­”\n"
      ],
      "metadata": {
        "id": "A6854lB_qRb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"ä½ æ˜¯è‚¡ç¥¨æ¨è–¦è«®è©¢å¸«ï¼Œè«‹æ ¹æ“šè³‡æ–™ä¾†å›æ‡‰ç”¨æˆ¶çš„å•é¡Œã€‚åªèƒ½ä½¿ç”¨å°ç£ç¿’æ…£çš„ç¹é«”ä¸­æ–‡å›æ‡‰ã€‚\"\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "æ ¹æ“šä¸‹åˆ—è³‡æ–™å›ç­”å•é¡Œï¼š\n",
        "{retrieved_chunks}\n",
        "\n",
        "ä½¿ç”¨è€…çš„å•é¡Œæ˜¯ï¼š{question}\n",
        "\n",
        "è«‹æ ¹æ“šè³‡æ–™å…§å®¹å›è¦†ï¼Œè‹¥è³‡æ–™ä¸è¶³è«‹å‘Šè¨´ç”¨æˆ¶å¯ä»¥ä¸Šç¶²æŸ¥è©¢ï¼Œä¸¦å‘ŠçŸ¥æ·±æ„ŸæŠ±æ­‰å¾ŒçºŒæœƒå†æ·»åŠ è³‡æ–™ä¸Šå»ã€‚\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "2Uv0tZS9htos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. ä½¿ç”¨ RAG ä¾†å›æ‡‰\n",
        "\n",
        "æœå°‹èˆ‡ä½¿ç”¨è€…å•é¡Œç›¸é—œçš„è³‡è¨Šï¼Œæ ¹æ“šæˆ‘å€‘çš„ prompt æ¨£ç‰ˆå»è®“ LLM å›æ‡‰ã€‚"
      ],
      "metadata": {
        "id": "qw8azlVESghL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "\n",
        "def chat_with_rag(user_input):\n",
        "    global chat_history\n",
        "    # å–å›ç›¸é—œè³‡æ–™\n",
        "    docs = retriever.get_relevant_documents(user_input)\n",
        "    retrieved_chunks = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
        "\n",
        "    # å°‡è‡ªå®š prompt å¥—å…¥æ ¼å¼\n",
        "    final_prompt = prompt_template.format(retrieved_chunks=retrieved_chunks, question=user_input)\n",
        "\n",
        "    # å‘¼å« OpenAI API\n",
        "    response = client.chat.completions.create(\n",
        "    model=model,\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": final_prompt},\n",
        "    ]\n",
        "    )\n",
        "    answer = response.choices[0].message.content\n",
        "\n",
        "    chat_history.append((user_input, answer))\n",
        "    return answer"
      ],
      "metadata": {
        "id": "pWfDUb3mD-6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. ç”¨ Gradio æ‰“é€  Web App"
      ],
      "metadata": {
        "id": "5m7E7XmgTJUr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "åœ¨å±•ç¤ºå°è©±åŒ¡textboxçš„éƒ¨åˆ†ï¼Œæˆ‘å€‘æœ‰çµ¦äºˆç”¨æˆ¶ä¸€äº›ç¯„ä¾‹ä½œçˆ²åƒè€ƒ\n",
        "\n",
        "åœ¨æå•æ™‚å¯ä»¥ä»¥é€™äº›ä½œç‚ºä¾‹å­ä¸‹å»æ›´æ”¹æå•"
      ],
      "metadata": {
        "id": "tuicKfec0a8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ğŸ“ˆğŸ“‰ è‚¡ç¥¨æ¨è–¦è«®è©¢å¸«\")\n",
        "    chatbot = gr.Chatbot()\n",
        "    msg = gr.Textbox(placeholder=\"è«‹è¼¸å…¥æ‚¨æƒ³è«®è©¢çš„å•é¡Œ...ï¼ˆå¦‚ï¼šå°ç©é›»çš„æœ¬ç›Šæ¯”æ˜¯å¤šå°‘ï¼Ÿå¯Œé‚¦çš„EPSæ˜¯å¤šå°‘ï¼ŸETFé«˜æ·¨å€¼è‚¡æ¨è–¦å¹¾éš»çµ¦æˆ‘ï¼Ÿè‚¡ç¥¨ç·¨è™Ÿ5534åŸºæœ¬è³‡æ–™ï¼Ÿç­‰ç­‰....ï¼‰\")\n",
        "\n",
        "    def respond(message, chat_history_local):\n",
        "        response = chat_with_rag(message)\n",
        "        chat_history_local.append((message, response))\n",
        "        return \"\", chat_history_local\n",
        "\n",
        "    msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "YI5swv4AFa_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tvhd9jYKFeGR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}